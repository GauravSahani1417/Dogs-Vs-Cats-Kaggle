{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Classification - Kaggle\n",
    "\n",
    "<br/>\n",
    "\n",
    "##### Kaggle Link - [https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the imports needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version - 1.12.0\n",
      "Keras Version - 2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from random import shuffle\n",
    "from time import time\n",
    "# tensorboard --logdir=logs/ --host localhost --port 8088\n",
    "\n",
    "print(f'TensorFlow Version - {tf.__version__}')\n",
    "print(f'Keras Version - {tf.keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train'\n",
    "TEST_DIR = 'data/test'\n",
    "IMG_SIZE = 50\n",
    "LR = 0.0003\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MODEL_NAME = 'dogs_cats_LR-{}_MODEL-{}.h5'.format(LR,'CovNet-128(2)-64(2)-32(2)-512-128-1')\n",
    "MODEL_PATH = os.path.join('saved_models',MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used model architecture for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(saved=True):\n",
    "    \"\"\"This method returns the model used.\n",
    "    Returns a saved model if MODEL_NAME is found.\n",
    "    CovNet Architecture\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    saved - Get the saved model from the MODEL_PATH if exists.(default True)\n",
    "    \n",
    "    Returns:\n",
    "    model - The complete uncompiled Keras model.\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    if os.path.isfile(MODEL_PATH) and saved :\n",
    "        print(\"Loading saved model {}\".format(MODEL_NAME))\n",
    "        return load_model(MODEL_PATH)\n",
    "    \n",
    "    # Declaring model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Block\n",
    "    model.add(Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 1),filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv1'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk1_mxPool'))\n",
    "\n",
    "    # 2nd Block\n",
    "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv1'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk2_mxPool'))\n",
    "    \n",
    "    # 3rd Block\n",
    "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv1'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk3_mxPool'))\n",
    "\n",
    "    # 4th Block - FC Block\n",
    "    dr_rate = 0.35\n",
    "    model.add(Flatten(name = 'blk4_flatten'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout1'))\n",
    "    model.add(Dense(512, activation='relu',name = 'blk4_dense1'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout2'))\n",
    "    model.add(Dense(128, activation='relu',name = 'blk4_dense2'))\n",
    "    model.add(Dropout(dr_rate,name = 'blk4_droupout3'))\n",
    "    model.add(Dense(1, activation='sigmoid',name = 'blk4_dense3'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(img):\n",
    "    \"\"\"Returns the label for an image.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    img - The filename of the image whose label we want to get.\n",
    "    \n",
    "    Returns:\n",
    "    list object - The respective label for dog or cat. (dog = 1, cat = 0)\n",
    "    \"\"\"\n",
    "    word = img.split('.')[0]\n",
    "    if word == 'cat':\n",
    "        return [0]\n",
    "    else:\n",
    "        return [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    \"\"\"Returns the training data from TRAIN_DIR.\n",
    "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\n",
    "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):\n",
    "        return np.load('training_data_{}.npy'.format(IMG_SIZE))\n",
    "    else:\n",
    "        for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "            label = get_label(img)\n",
    "            path = os.path.join(TRAIN_DIR,img)\n",
    "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n",
    "            img = img/255\n",
    "            training_data.append([np.array(img),np.array(label)])\n",
    "        shuffle(training_data)\n",
    "        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)\n",
    "        return np.array(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testing_data():\n",
    "    \"\"\"Returns the testing data from TEST_DIR.\n",
    "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\n",
    "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\n",
    "    \"\"\"\n",
    "    testing_data = []\n",
    "    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):\n",
    "        return np.load('testing_data_{}.npy'.format(IMG_SIZE))\n",
    "    else:\n",
    "        for img in tqdm(os.listdir(TEST_DIR)):\n",
    "            img_id = int(img.split('.')[0])\n",
    "            path = os.path.join(TEST_DIR,img)\n",
    "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n",
    "            img = img/255\n",
    "            testing_data.append([np.array(img),img_id])\n",
    "        testing_data.sort(key = lambda x: x[1])\n",
    "        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)\n",
    "        return np.array(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_training_data()\n",
    "\n",
    "partition = 1000             # Breaking -ve index\n",
    "train = data[:-partition]    # For Training purpose\n",
    "test= data[-partition:]      # For Validation purpose\n",
    "\n",
    "# Training set\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y_train = np.array([i[1] for i in train])\n",
    "\n",
    "# Validation set\n",
    "X_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y_val = np.array([i[1] for i in test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Effects added on image\n",
    "    Rotation - ± 50 deegrees,\n",
    "    Width Shift - ± 15 %\n",
    "    Height Shift - ± 15 %\n",
    "    Zoom - 30%\n",
    "    Horizontal Flip\n",
    "    Vertical Flip\n",
    "\"\"\"\n",
    "datagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.05,height_shift_range=0.05,\n",
    "                            zoom_range=0.05,horizontal_flip=True,vertical_flip=False)\n",
    "\n",
    "# Calculation of necessary internal data for all images.\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "blk1_conv1 (Conv2D)          (None, 50, 50, 128)       3328      \n",
      "_________________________________________________________________\n",
      "blk1_conv2 (Conv2D)          (None, 50, 50, 128)       409728    \n",
      "_________________________________________________________________\n",
      "blk1_mxPool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "blk2_conv1 (Conv2D)          (None, 25, 25, 64)        204864    \n",
      "_________________________________________________________________\n",
      "blk2_conv2 (Conv2D)          (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "blk2_mxPool (MaxPooling2D)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "blk3_conv1 (Conv2D)          (None, 12, 12, 32)        51232     \n",
      "_________________________________________________________________\n",
      "blk3_conv2 (Conv2D)          (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "blk3_mxPool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "blk4_flatten (Flatten)       (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "blk4_droupout1 (Dropout)     (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "blk4_dense1 (Dense)          (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "blk4_droupout2 (Dropout)     (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "blk4_dense2 (Dense)          (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "blk4_droupout3 (Dropout)     (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "blk4_dense3 (Dense)          (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,453,377\n",
      "Trainable params: 1,453,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer (Adam Optimizer)\n",
    "adam = Adam(lr = LR)\n",
    "\n",
    "# Callbacks Declared\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),batch_size=BATCH_SIZE)\n",
    "       #Supported in new version of keras ,update_freq='epoch')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.3,patience=3,verbose=1,\n",
    "                              mode='max', min_lr=0.000001)\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min')\n",
    "      #Supported in new version of keras ,restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_PATH,monitor='val_acc',verbose=1,save_best_only=True,\n",
    "                                  mode='max',period=3)\n",
    "\n",
    "model.compile(optimizer = adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5 using Image Augmentation\n",
      "Epoch 1/30\n",
      " - 58s - loss: 0.6717 - acc: 0.5829 - val_loss: 0.5819 - val_acc: 0.6950\n",
      "Epoch 2/30\n",
      " - 53s - loss: 0.5979 - acc: 0.6854 - val_loss: 0.5118 - val_acc: 0.7590\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: val_acc improved from -inf to 0.79100, saving model to saved_models\\dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5\n",
      " - 54s - loss: 0.5629 - acc: 0.7153 - val_loss: 0.4862 - val_acc: 0.7910\n",
      "Epoch 4/30\n",
      " - 52s - loss: 0.5349 - acc: 0.7364 - val_loss: 0.4566 - val_acc: 0.7920\n",
      "Epoch 5/30\n",
      " - 53s - loss: 0.5158 - acc: 0.7460 - val_loss: 0.4567 - val_acc: 0.7840\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.79100 to 0.80700, saving model to saved_models\\dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5\n",
      " - 52s - loss: 0.4994 - acc: 0.7583 - val_loss: 0.4160 - val_acc: 0.8070\n",
      "Epoch 7/30\n",
      " - 51s - loss: 0.4807 - acc: 0.7749 - val_loss: 0.4226 - val_acc: 0.8040\n",
      "Epoch 8/30\n",
      " - 52s - loss: 0.4700 - acc: 0.7772 - val_loss: 0.4219 - val_acc: 0.8010\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.80700 to 0.82700, saving model to saved_models\\dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5\n",
      " - 52s - loss: 0.4614 - acc: 0.7850 - val_loss: 0.3738 - val_acc: 0.8270\n",
      "Epoch 10/30\n",
      " - 54s - loss: 0.4409 - acc: 0.7967 - val_loss: 0.5448 - val_acc: 0.7530\n",
      "Epoch 11/30\n",
      " - 53s - loss: 0.4380 - acc: 0.7970 - val_loss: 0.4914 - val_acc: 0.7640\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82700\n",
      " - 53s - loss: 0.4340 - acc: 0.8010 - val_loss: 0.4057 - val_acc: 0.8060\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Toggle if dont want to train using Image Augmentation\n",
    "generator_train = True\n",
    "EPOCHS = 30\n",
    "callbacks=[tensorboard,reduce_lr,early_stop,model_checkpoint]\n",
    "\n",
    "if generator_train:\n",
    "    print(f'Training model {MODEL_NAME} using Image Augmentation')\n",
    "    hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=BATCH_SIZE),\n",
    "                               steps_per_epoch=len(X_train)//BATCH_SIZE,epochs=EPOCHS,verbose=2,\n",
    "                               validation_data=(X_val,y_val),callbacks=callbacks)\n",
    "else:\n",
    "    print(f'Training model {MODEL_NAME} using normal image data provided')\n",
    "    hist = model.fit(X_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(X_val,y_val),\n",
    "                     verbose=2,callbacks=callbacks)\n",
    "#model.save(MODEL_PATH)     Redundant Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = get_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "ids = [i[1] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the final submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'submission-{}.csv'.format(time())\n",
    "\n",
    "with open(filename,'w') as f:\n",
    "    f.write('id,label\\n')\n",
    "with open(filename,'a') as f:\n",
    "    for i in range(len(X_test)):\n",
    "        f.write('{},{}\\n'.format(ids[i],pred[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Submission_Result.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
